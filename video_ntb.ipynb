{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from espcn_pytorch import ESPCN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio(video_in, audio_out):\n",
    "    subprocess.run(['ffmpeg', '-i', video_in, '-acodec', 'copy', audio_out])\n",
    "\n",
    "\n",
    "def add_audio(video_in, audio_in, video_out):\n",
    "    print(f'adding audio to {video_out}')\n",
    "    subprocess.run(['ffmpeg', '-i', video_in, '-i', audio_in, '-c:a', 'copy', '-c:v', 'libx264', '-crf', '20', '-preset', 'veryslow', '-bsf:a', 'aac_adtstoasc', '-profile:v', 'main', video_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     109,
     138
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# config\n",
    "tmp_dir = 'tmp'\n",
    "out_dir = 'out'\n",
    "\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "args_cuda = True\n",
    "args_scale_factor = 2\n",
    "args_weights = f'weights/espcn_{args_scale_factor}x.pth'\n",
    "\n",
    "division_factor = 0.5\n",
    "\n",
    "if sys.argv[1] == '-f':\n",
    "    video_name = 'sequences/buh_00_01_00.mp4'\n",
    "else:\n",
    "    video_name = sys.argv[1]\n",
    "args_view = False\n",
    "args_compare = False\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "file_name_bare = os.path.basename(video_name).strip('.mp4')\n",
    "\n",
    "# rest of code\n",
    "\n",
    "if torch.cuda.is_available() and not args_cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "torch.set_num_threads(8)\n",
    "\n",
    "device = torch.device(\"cuda:\"+str(int(os.environ.get('index', '0'))%4) if args_cuda else \"cpu\")\n",
    "print(video_name, '-', device)\n",
    "\n",
    "# create model\n",
    "model = ESPCN(scale_factor=args_scale_factor).to(device)\n",
    "\n",
    "# Load state dicts\n",
    "model.load_state_dict(torch.load(args_weights, map_location=device))\n",
    "\n",
    "# Set model eval mode\n",
    "model.eval()\n",
    "\n",
    "# img preprocessing operation\n",
    "pil2tensor = transforms.ToTensor()\n",
    "tensor2pil = transforms.ToPILImage()\n",
    "\n",
    "# Open video file\n",
    "print('Extracting audio')\n",
    "audio_path = f'{tmp_dir}/{file_name_bare}.aac'\n",
    "extract_audio(video_name, audio_path)\n",
    "\n",
    "print(f\"Reading `{os.path.basename(video_name)}`...\")\n",
    "video_capture = cv2.VideoCapture(video_name)\n",
    "# Prepare to write the processed image into the video.\n",
    "fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# Set video size\n",
    "size = (int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "sr_size = (size[0] * args_scale_factor, size[1] * args_scale_factor)\n",
    "pare_size = (sr_size[0] * 2 + 10, sr_size[1] + 10 + sr_size[0] // 5 - 9)\n",
    "# Video write loader.\n",
    "fn = f\"{tmp_dir}/{file_name_bare}_{args_scale_factor}x\"\n",
    "\n",
    "fn_side_by_side = f\"{fn}_side_by_side.mp4\"\n",
    "fn_srgan = f\"{fn}_espcn.mp4\"\n",
    "fn_compare = f\"{fn}_compare.mp4\"\n",
    "\n",
    "srgan_writer = cv2.VideoWriter(fn_srgan,\n",
    "                               cv2.VideoWriter_fourcc(*\"MPEG\"), fps, sr_size)\n",
    "if args_compare:\n",
    "    compare_writer = cv2.VideoWriter(fn_compare,\n",
    "                                     cv2.VideoWriter_fourcc(*\"MPEG\"), fps, pare_size)\n",
    "sidebyside_writer = cv2.VideoWriter(fn_side_by_side,\n",
    "                               cv2.VideoWriter_fourcc(*\"MPEG\"), fps, sr_size)\n",
    "\n",
    "def merge(a, b, split=0.5):\n",
    "    h = int(a.shape[1]*split)\n",
    "    a[:,h:,:] = b[:,h:,:]\n",
    "    a[:,h-1:h,:] = 255\n",
    "\n",
    "# read frame\n",
    "success, raw_frame = video_capture.read()\n",
    "#print('success', success)\n",
    "progress_bar = tqdm(range(total_frames), desc=\"[processing video and saving/view result videos]\")\n",
    "for index in progress_bar:\n",
    "    if success:\n",
    "        img = Image.fromarray(cv2.cvtColor(raw_frame, cv2.COLOR_BGR2RGB)).convert(\"YCbCr\")\n",
    "        y, cb, cr = img.split()\n",
    "        img = pil2tensor(y).view(1, -1, y.size[1], y.size[0])\n",
    "        img = img.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prediction = model(img)\n",
    "\n",
    "        prediction = prediction.cpu()\n",
    "        sr_frame_y = prediction[0].detach().numpy()\n",
    "        sr_frame_y *= 255.0\n",
    "        sr_frame_y = sr_frame_y.clip(0, 255)\n",
    "        sr_frame_y = Image.fromarray(np.uint8(sr_frame_y[0]), mode=\"L\")\n",
    "\n",
    "        sr_frame_cb = cb.resize(sr_frame_y.size, Image.BICUBIC)\n",
    "        sr_frame_cr = cr.resize(sr_frame_y.size, Image.BICUBIC)\n",
    "        sr_frame = Image.merge(\"YCbCr\", [sr_frame_y, sr_frame_cb, sr_frame_cr]).convert(\"RGB\")\n",
    "        # before converting the result in RGB\n",
    "        sr_frame = cv2.cvtColor(np.asarray(sr_frame), cv2.COLOR_RGB2BGR)\n",
    "        # save sr video\n",
    "        srgan_writer.write(sr_frame)\n",
    "\n",
    "        upscaled_img = cv2.resize(raw_frame, sr_size)\n",
    "        #merge(upscaled_img, sr_frame, np.sin(index/40)/5+0.5)\n",
    "        merge(upscaled_img, sr_frame, division_factor)\n",
    "        sidebyside_writer.write(upscaled_img)\n",
    "        if args_compare:\n",
    "        \n",
    "            # make compared video and crop shot of left top\\right top\\center\\left bottom\\right bottom\n",
    "            sr_frame = tensor2pil(sr_frame)\n",
    "            # Five areas are selected as the bottom contrast map.\n",
    "            crop_sr_imgs = transforms.FiveCrop(size=sr_frame.width // 5 - 9)(sr_frame)\n",
    "            crop_sr_imgs = [np.asarray(transforms.Pad(padding=(10, 5, 0, 0))(img)) for img in crop_sr_imgs]\n",
    "            sr_frame = transforms.Pad(padding=(5, 0, 0, 5))(sr_frame)\n",
    "            # Five areas in the contrast map are selected as the bottom contrast map\n",
    "            compare_img = transforms.Resize((sr_size[1], sr_size[0]), interpolation=Image.BICUBIC)(tensor2pil(raw_frame))\n",
    "            crop_compare_imgs = transforms.FiveCrop(size=compare_img.width // 5 - 9)(compare_img)\n",
    "            crop_compare_imgs = [np.asarray(transforms.Pad(padding=(0, 5, 10, 0))(img)) for img in crop_compare_imgs]\n",
    "            compare_img = transforms.Pad(padding=(0, 0, 5, 5))(compare_img)\n",
    "            # concatenate all the pictures to one single picture\n",
    "            # 1. Mosaic the left and right images of the video.\n",
    "            top_img = np.concatenate((np.asarray(compare_img), np.asarray(sr_frame)), axis=1)\n",
    "            # 2. Mosaic the bottom left and bottom right images of the video.\n",
    "            bottom_img = np.concatenate(crop_compare_imgs + crop_sr_imgs, axis=1)\n",
    "            bottom_img_height = int(top_img.shape[1] / bottom_img.shape[1] * bottom_img.shape[0])\n",
    "            bottom_img_width = top_img.shape[1]\n",
    "            # 3. Adjust to the right size.\n",
    "            bottom_img = np.asarray(transforms.Resize((bottom_img_height, bottom_img_width))(tensor2pil(bottom_img)))\n",
    "\n",
    "\n",
    "            # 4. Combine the bottom zone with the upper zone.\n",
    "            final_image = np.concatenate((top_img, bottom_img))\n",
    "\n",
    "            compare_writer.write(final_image)\n",
    "\n",
    "        if args_view:\n",
    "            # display video\n",
    "            cv2.imshow(\"LR video convert HR video \", final_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "    # next frame\n",
    "    success, raw_frame = video_capture.read()\n",
    "sidebyside_writer.release()\n",
    "compare_writer.release()\n",
    "srgan_writer.release()\n",
    "print('combining with audio')\n",
    "fn_out = f\"{out_dir}/{file_name_bare}_{args_scale_factor}x\"\n",
    "\n",
    "fn_out_side_by_side = f\"{fn_out}_side_by_side.mp4\"\n",
    "fn_out_srgan = f\"{fn_out}_espcn.mp4\"\n",
    "fn_out_compare = f\"{fn_out}_compare.mp4\"\n",
    "\n",
    "add_audio(fn_side_by_side, audio_path, fn_out_side_by_side)\n",
    "add_audio(fn_srgan, audio_path, fn_out_srgan)\n",
    "if args_compare:\n",
    "    add_audio(fn_compare, audio_path, fn_out_compare)\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "espcn",
   "language": "python",
   "name": "espcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
